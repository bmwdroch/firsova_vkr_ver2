# Классификация клиентов Acoola по уровню лояльности

## Описание проекта

Проект направлен на разработку системы классификации клиентов компании Acoola по уровню лояльности с использованием методов машинного обучения. Система позволяет анализировать поведение клиентов, оценивать их лояльность и предоставлять рекомендации по взаимодействию с различными сегментами клиентской базы.

## Текущий статус проекта

В настоящее время ведется работа над задачей **TASK-007: Оптимизация и валидация моделей**. Основные этапы, такие как анализ предметной области, EDA, предобработка данных, разработка признака лояльности и базовое обучение моделей, завершены.

## Структура проекта

```
firsova_vkr/
├── .cursor/                     # Настройки Cursor IDE
├── .venv/                       # Виртуальное окружение Python
├── config/                      # Конфигурационные файлы
│   ├── app/                     # Конфигурация приложения (в перспективе)
│   └── model/                   # Конфигурация моделей (в перспективе)
├── dataset/                     # Датасеты
│   ├── raw/                     # Сырые данные (например, Concept202408.csv)
│   ├── processed/               # Обработанные данные (результаты шага предобработки)
│   └── external/                # Внешние данные (если будут использоваться)
├── docs/                        # Документация проекта
│   ├── business/                # Бизнес-документация
│   ├── research/                # Исследовательская документация (например, обзоры методов)
│   └── technical/               # Техническая документация
│       ├── api/                 # Документация API (в перспективе)
│       ├── architecture/        # Описание архитектуры (например, application_architecture.md)
│       └── models/              # Описание моделей
├── notebooks/                   # Jupyter notebooks (для исследовательских целей, если используются)
│   ├── exploration/
│   ├── modeling/
│   └── visualization/
├── output/                      # Выходные данные работы скриптов и моделей
│   ├── demo/                    # Результаты демонстрационных запусков
│   ├── models/                  # Сохраненные (сериализованные) модели
│   ├── reports/                 # Отчеты (например, метрики, графики)
│   └── results/                 # Результаты экспериментов
│       └── plots/               # Графики (например, важность признаков)
├── scripts/                     # Вспомогательные скрипты (постепенно заменяются основным пайплайном)
│   ├── data/
│   ├── deployment/
│   └── setup/
├── src/                         # Исходный код основного приложения и модулей
│   ├── api/                     # API приложения (TASK-009, разработка в перспективе)
│   │   ├── middleware/
│   │   ├── routes/
│   │   └── schemas/
│   ├── data/                    # Модули для работы с данными
│   │   ├── loaders/             # Загрузчики данных
│   │   ├── processors/          # Обработчики данных
│   │   └── validators/          # Валидаторы данных
│   ├── gui/                     # Графический интерфейс (TASK-010, отложено)
│   │   ├── assets/
│   │   ├── components/
│   │   └── screens/
│   ├── modeling/                # Модули, связанные с ML-моделями
│   │   ├── evaluation/          # Оценка моделей (model_evaluation.py)
│   │   ├── interpretation/      # Интерпретация моделей (например, SHAP)
│   │   ├── models/              # (Возможно, для кастомных реализаций моделей)
│   │   ├── optimization/        # Оптимизация гиперпараметров (model_optimization.py)
│   │   └── model_training.py    # Основной модуль обучения моделей
│   ├── preprocessing/           # Модули предобработки данных
│   │   ├── cleaners/
│   │   ├── encoders/
│   │   ├── feature_engineering/ # (enhanced_loyalty_features.py)
│   │   └── data_preprocessing.py # Основной модуль предобработки
│   ├── utils/                   # Вспомогательные утилиты
│   │   ├── config/
│   │   ├── helpers/
│   │   └── logging/
│   └── visualization/           # Модули для визуализации
│       ├── dashboards/
│       └── plots/
├── tests/                       # Тесты
│   ├── unit/                    # Модульные тесты
│   ├── integration/             # Интеграционные тесты
│   └── e2e/                     # End-to-end тесты
├── .gitattributes
├── .gitignore
├── README.md                    # Этот файл
├── requirements.md              # Заметки по зависимостям (возможно, устарел)
├── requirements.txt             # Файл зависимостей Python
├── workflow_state.md            # Файл для отслеживания состояния проекта и задач
└── plan_course_work.md          # Первоначальный план (возможно, устарел)
```

## Установка и настройка

1.  Клонируйте репозиторий (если еще не сделали):
    ```bash
    git clone https://github.com/username/firsova_vkr.git
    cd firsova_vkr
    ```

2.  Создайте виртуальное окружение и активируйте его (рекомендуется Python 3.13 или выше):
    ```bash
    python -m venv .venv
    # Linux/Mac
    source .venv/bin/activate
    # Windows (PowerShell)
    .venv\Scripts\Activate.ps1
    # Windows (cmd.exe)
    .venv\Scripts\activate.bat
    ```

3.  Установите зависимости:
    ```bash
    pip install -r requirements.txt
    ```

4.  (Опционально) Настройте конфигурацию:
    Проект стремится минимизировать сложную настройку через конфигурационные файлы для основных сценариев. Параметры передаются через аргументы командной строки.

## Использование

Основной способ взаимодействия с проектом — через главный скрипт `src/run_pipeline.py`.

### Запуск полного пайплайна

Для запуска полного пайплайна, включающего предобработку данных, создание признаков лояльности, обучение и оценку моделей:
```bash
python src/run_pipeline.py --input_file dataset/raw/Concept202408.csv --output_dir output --save_intermediate
```
*   Убедитесь, что файл `Concept202408.csv` находится в `dataset/raw/`. Если имя файла или путь отличаются, укажите корректный `--input_file`.

### Опции запуска пайплайна

Скрипт `src/run_pipeline.py` поддерживает различные флаги для управления этапами выполнения:

*   `--input_file TEXT`: Путь к исходному файлу CSV. (Обязательный)
*   `--output_dir TEXT`: Директория для сохранения результатов. По умолчанию `output`.
*   `--skip_preprocessing`: Пропустить этап предобработки данных.
*   `--skip_loyalty_features`: Пропустить этап создания признаков лояльности.
*   `--skip_model_training`: Пропустить этап обучения моделей.
*   `--tune_hyperparams`: Включить оптимизацию гиперпараметров с использованием Optuna.
*   `--n_opt_trials INTEGER`: Количество итераций для Optuna. По умолчанию 10.
*   `--cv_opt_folds INTEGER`: Количество фолдов кросс-валидации при оптимизации. По умолчанию 3.
*   `--create_ensemble`: Создать ансамблевые модели.
*   `--balance_classes TEXT`: Метод балансировки классов (например, 'smote', 'random_oversample').
*   `--save_intermediate`: Сохранять промежуточные датасеты.
*   `--random_state INTEGER`: Seed для генератора случайных чисел. По умолчанию 42.
*   `--test_size FLOAT`: Размер тестовой выборки. По умолчанию 0.2.
*   `--loyalty_metric TEXT`: Метрика для оптимизации (например, `f1_macro`, `roc_auc_ovr`). По умолчанию `f1_macro`.

**Пример:** Запуск оптимизации гиперпараметров для моделей, пропуская предобработку (если данные уже подготовлены):
```bash
python src/run_pipeline.py --input_file dataset/processed/preprocessed_data.pkl --skip_preprocessing --tune_hyperparams --n_opt_trials 50
```

## Технологический стек (основные библиотеки)

- Python 3.13+
- pandas
- numpy
- scikit-learn
- matplotlib
- seaborn
- XGBoost
- LightGBM
- Optuna (для оптимизации гиперпараметров)
- SHAP (для интерпретации моделей)
- imbalanced-learn (для балансировки классов)

Полный список зависимостей указан в файле `requirements.txt`.

## Разработка

### Запуск тестов (в перспективе)
```bash
pytest tests/
```

### Форматирование кода (рекомендация)
Рекомендуется использовать `black` для форматирования кода.
```bash
black src/ tests/
```

## Лицензия

MIT (Предполагается, уточните если другая)

## Авторы
