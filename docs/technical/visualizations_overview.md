# Обзор визуализаций проекта

В проекте генерируется несколько типов визуализаций, которые помогают понять данные, оценить качество моделей и интерпретировать их результаты. Они сохраняются в различных поддиректориях `output/`.

## 1. Визуализации из `output/visualizations/`

Эти графики в основном генерируются на этапе анализа и формирования улучшенного признака лояльности (`src/preprocessing/enhanced_loyalty_features.py`).

*   **`loyalty_categories_distribution.png`**: Столбчатая диаграмма, показывающая распределение клиентов по финальным категориям лояльности (например, "Высоколояльные", "Отток" и т.д.). Помогает оценить сбалансированность итоговых классов.
*   **`loyalty_score_distribution.png`**: Гистограмма, иллюстрирующая распределение непрерывного значения `enhanced_loyalty_score`. На этом графике также могут быть отмечены вертикальными линиями границы, по которым этот скор был разделен на дискретные категории.

## 2. Визуализации из `output/feature_importance/visualizations/`

Эти визуализации создаются функцией `evaluate_feature_importance` из `src/preprocessing/enhanced_loyalty_features.py` и служат для оценки и интерпретации важности признаков.

*   **`feature_importance_correlation.png`**: Столбчатая диаграмма, отображающая топ-N признаков, отсортированных по их комбинированной оценке корреляции (включая корреляцию Пирсона и взаимную информацию) с целевой переменной.
*   **`feature_importance_integrated.png`**: Столбчатая диаграмма, показывающая топ-N признаков на основе интегральной оценки их важности (усредненной по нескольким методам: корреляции, важность из Random Forest, Permutation Importance, SHAP).
*   **`feature_importance_permutation.png`**: Столбчатая диаграмма важности признаков, полученная с помощью метода Permutation Importance. Этот метод оценивает падение качества модели при случайном перемешивании значений одного признака.
*   **`shap_summary.png`**: Сводный график SHAP values (обычно `summary_plot` типа "bar"). Он показывает среднее абсолютное влияние каждого признака на предсказание модели (той, что использовалась для расчета SHAP, например, Random Forest). Помогает понять, какие признаки в среднем наиболее сильно сдвигают предсказание.
*   **`shap_dependence_ИМЯ_ПРИЗНАКА.png`** (например, `shap_dependence_recency.png`): Графики зависимости SHAP (dependence plots) для конкретных признаков. Они показывают, как изменение значения одного признака влияет на SHAP value (и, следовательно, на предсказание) для отдельных наблюдений. Часто на этих графиках также отображается взаимодействие с другим признаком.

## 3. Визуализации из `output/results/plots/`

Эти графики генерируются на этапе обучения и оценки моделей (`src/run_pipeline.py` и `src/modeling/model_evaluation.py`).

*   **`feature_importance_ИМЯ_МОДЕЛИ_ДАТА_ВРЕМЯ.png`** (например, `feature_importance_lightgbm_20250510_140400.png`): Графики важности признаков, специфичные для конкретной обученной модели (LightGBM, XGBoost, Random Forest). Показывают, какие признаки данная модель считает наиболее влиятельными при принятии решений.
*   **`metrics_comparison_ДАТА_ВРЕМЯ.png`**: Сравнительные графики различных метрик качества (например, F1-score, Precision, Recall, Accuracy) для всех моделей, обученных в рамках одного запуска пайплайна. Помогают визуально определить, какая модель показала наилучшие результаты.

Дополнительно, модуль `model_evaluation.py` может генерировать (но это зависит от конфигурации запуска):
*   **Матрицы ошибок (Confusion Matrices)**: Показывают количество верных и неверных классификаций для каждого класса.
*   **ROC-кривые (Receiver Operating Characteristic curves)**: Иллюстрируют качество бинарной классификации при различных порогах отсечения.
*   **PR-кривые (Precision-Recall curves)**: Показывают соотношение точности и полноты при различных порогах, особенно полезны для несбалансированных наборов данных. 