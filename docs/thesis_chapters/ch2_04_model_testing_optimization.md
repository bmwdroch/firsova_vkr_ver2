# Глава 2. Разработка моделей машинного обучения

## 2.4 Тестирование моделей и оптимизация

После первоначального обучения и оценки базового набора моделей машинного обучения, следующим критически важным этапом стала их детальная оптимизация и всестороннее тестирование. Основная цель этого этапа – добиться максимальной предсказательной способности моделей, обеспечить их устойчивость и надежность, а также глубоко проанализировать факторы, влияющие на их решения.

### 2.4.1 Оптимизация гиперпараметров моделей

Качество работы моделей машинного обучения в значительной степени зависит от корректного подбора их гиперпараметров – настроек, которые не вычисляются в процессе обучения, а задаются до его начала. Для системного и эффективного поиска оптимальных комбинаций гиперпараметров для наиболее перспективных моделей (Random Forest, XGBoost и LightGBM) был использован фреймворк **Optuna**.

Процесс оптимизации с использованием Optuna включал следующие шаги:
1.  **Определение пространства поиска гиперпараметров:** Для каждой модели (RandomForest, XGBoost, LightGBM) были заданы диапазоны и типы распределений для ключевых гиперпараметров (например, количество деревьев, глубина деревьев, скорость обучения, параметры регуляризации и т.д.). Эта информация была определена в функциях `rf_param_distributions`, `xgb_param_distributions`, `lgbm_param_distributions` модуля `src/modeling/optimization/model_optimization.py` (согласно TASK-007-6).
2.  **Выбор целевой метрики:** В качестве основной метрики для оптимизации была выбрана **F1-macro**, поскольку она хорошо подходит для задач с несбалансированными классами, усредняя F1-меру по всем классам.
3.  **Применение кросс-валидации:** Для получения более робастной оценки качества модели при каждом наборе гиперпараметров внутри процесса оптимизации применялась k-блочная кросс-валидация (в данном случае, с `cv_opt_folds`, например, 3 или 5 фолдов, как указано в аргументах запуска `--cv_opt_folds`). Это позволяет снизить риск переобучения на конкретное разбиение данных.
4.  **Итеративный поиск:** Optuna проводила заданное количество итераций (`n_opt_trials`, например, 5-20 испытаний, как указано в аргументах запуска `--n_opt_trials`), на каждой из которых выбирался новый набор гиперпараметров, модель обучалась и оценивалась с помощью кросс-валидации. Optuna использует интеллектуальные алгоритмы сэмплирования (например, TPE - Tree-structured Parzen Estimator) для эффективного исследования пространства поиска.
5.  **Выбор лучших параметров:** По завершении всех испытаний Optuna возвращала набор гиперпараметров, показавший наилучшее значение целевой метрики F1-macro. Эти оптимизированные параметры затем использовались для финального обучения соответствующей модели.

Лог выполнения (`output/results/log.txt`) содержит детальную информацию о ходе оптимизации для каждой из этих моделей.

### 2.4.2 Кросс-валидация как метод оценки обобщающей способности

Помимо использования кросс-валидации внутри процесса оптимизации гиперпараметров, она также применялась как основной метод оценки обобщающей способности финальных моделей. K-блочная кросс-валидация позволяет получить более надежную оценку того, как модель будет работать на новых, ранее не виданных данных, по сравнению с однократным разбиением на обучающую и тестовую выборки.

### 2.4.3 Результаты оптимизации и выбор лучшей модели

После проведения оптимизации гиперпараметров и всесторонней оценки, была выбрана наилучшая модель для решения задачи классификации клиентов по уровню их лояльности. Согласно данным из лога выполнения, наилучшие результаты продемонстрировала модель **LightGBM**.

Метрики качества для лучшей модели (LightGBM) на тестовой выборке составили:
*   **Accuracy:** 1.0000
*   **Precision (macro):** 1.0000
*   **Recall (macro):** 1.0000
*   **F1-score (macro):** 1.0000

Столь высокие, фактически идеальные, значения метрик требуют особого комментария. Как было отмечено при анализе результатов формирования целевой переменной `enhanced_loyalty_score` и ее последующей категоризации (см. Раздел 2.2.4 и запись [PIPELINE-RUN-1] в `workflow_state.md`), используемый метод квантильного разделения на две категории ('Высоколояльные' и 'Отток') привел к сильному дисбалансу классов (87.37% 'Высоколояльные' и 12.63% 'Отток'). Вероятно, особенности расчета `enhanced_loyalty_score` (где многие значения могли быть обрезаны до максимального или минимального предела перед категоризацией) и последующее разделение на всего две категории сделали задачу классификации относительно простой для мощных алгоритмов, таких как LightGBM, особенно после отбора признаков, сильно коррелирующих с таким образом сформированной целевой переменной. На данном этапе проекта было принято решение зафиксировать этот результат и не проводить дальнейшую модификацию логики расчета `enhanced_loyalty_score` или методов категоризации, сосредоточившись на других аспектах системы. Важно понимать, что в реальных условиях при более сложной и гранулированной целевой переменной метрики, скорее всего, были бы ниже.

Сравнительный анализ метрик различных моделей мог быть визуализирован (например, с помощью `metrics_comparison_ДАТА_ВРЕМЯ.png` из `output/results/plots/`, см. `docs/technical/visualizations_overview.md`), что позволяет наглядно сравнить производительность моделей до и после оптимизации.

### 2.4.4 Интерпретация моделей и анализ важности признаков

Понимание того, какие признаки вносят наибольший вклад в предсказания модели, является ключевым для оценки ее адекватности и получения ценных бизнес-инсайтов. Для интерпретации моделей и анализа важности признаков использовались следующие подходы:

*   **Встроенная важность признаков:** Модели, основанные на деревьях решений (Random Forest, XGBoost, LightGBM), предоставляют внутреннюю оценку важности признаков (обычно на основе того, как часто признак используется для разбиения в деревьях и насколько сильно он улучшает метрику). Эти результаты визуализировались и сохранялись (например, `feature_importance_lightgbm_ДАТА_ВРЕМЯ.png` в `output/results/plots/`, см. `docs/technical/visualizations_overview.md`).
*   **Permutation Importance:** Этот метод оценивает важность признака путем измерения падения качества модели после случайного перемешивания значений данного признака в тестовой выборке. Чем сильнее падает качество, тем важнее признак. Результаты этого анализа также визуализировались (например, `feature_importance_permutation.png` в `output/feature_importance/visualizations/`).
*   **SHAP (SHapley Additive exPlanations):** Мощный метод, основанный на теории игр (значениях Шепли), который позволяет объяснить предсказание для каждого отдельного наблюдения как сумму вкладов каждого признака. SHAP values показывают не только величину вклада, но и его направление. Для анализа использовались сводные графики SHAP (например, `shap_summary.png`), показывающие среднее абсолютное влияние каждого признака, и графики зависимостей (например, `shap_dependence_ИМЯ_ПРИЗНАКА.png`), иллюстрирующие, как изменение значения признака влияет на предсказание. Эти визуализации можно найти в `output/feature_importance/visualizations/`.

Анализ важности признаков, проведенный на этапе подготовки данных (см. Раздел 2.2.5) и подтвержденный при оценке моделей, выявил, что наибольший вклад вносят такие признаки, как `recency_ratio` (отношение давности последней покупки к среднему), `monetary` (общая сумма покупок), `pca_component_3` (третья главная компонента), `recency` (давность последней покупки), `pca_component_1` (первая главная компонента), `cluster` (присвоенный кластер клиента), `frequency` (частота покупок), `purchase_density` (плотность покупок) и другие. Полный отчет по важности признаков сохранялся в `output/feature_importance/feature_importance.csv`.

### 2.4.5 Анализ ошибок классификации

Хотя в данном конкретном запуске пайплайна модели показали идеальные метрики на тестовой выборке, в общем случае важным этапом является анализ ошибок классификации. Это включает изучение матрицы ошибок (Confusion Matrix, см. `docs/technical/visualizations_overview.md` – ModelEvaluator может их генерировать) для понимания, какие классы модели путают чаще, и анализ индивидуальных случаев неверной классификации для выявления возможных аномалий в данных, неадекватности признаков или специфических паттернов, которые модель не смогла уловить. Такой анализ может дать направление для дальнейшего улучшения моделей или процессов подготовки данных.

### 2.4.6 Сохранение лучшей модели

Лучшая оптимизированная модель (LightGBM) со всеми ее параметрами и предобученными трансформерами была сохранена в файл `output/models/best_model.pkl`. Это позволяет в дальнейшем легко загружать модель для применения на новых данных или для интеграции в приложение без необходимости повторного обучения.

Таким образом, этап тестирования и оптимизации позволил не только выбрать наиболее производительную модель, но и получить представление о факторах, определяющих лояльность клиентов, а также подготовить модель к практическому использованию. 