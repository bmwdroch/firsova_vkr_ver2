# Глава 2. Разработка моделей машинного обучения

## 2.3 Разработка моделей машинного обучения

После завершения этапа подготовки и конструирования признаков, основной задачей стало построение и оценка различных моделей машинного обучения для классификации клиентов по уровню их лояльности. Целью данного этапа являлся выбор наиболее эффективных алгоритмов, способных точно идентифицировать различные сегменты клиентов.

### 2.3.1 Выбор моделей для исследования

На основе анализа литературы и распространенных практик в задачах классификации, для исследования были выбраны следующие алгоритмы машинного обучения:

*   **Логистическая регрессия:** Как базовый (baseline) линейный классификатор, простой в интерпретации и быстрый в обучении.
*   **Случайный лес (Random Forest):** Ансамблевый метод, основанный на построении множества решающих деревьев, известный своей устойчивостью к переобучению и высокой точностью.
*   **Градиентный бустинг:** Мощный ансамблевый метод, последовательно строящий модели, где каждая последующая модель корректирует ошибки предыдущей. Были рассмотрены его популярные реализации:
    *   Стандартный `GradientBoostingClassifier` из scikit-learn.
    *   **XGBoost:** Оптимизированная распределенная библиотека градиентного бустинга, известная своей производительностью и эффективностью.
    *   **LightGBM:** Еще одна высокопроизводительная реализация градиентного бустинга, использующая гистограммные методы для ускорения обучения и уменьшения потребления памяти.
*   **Метод опорных векторов (SVM):** Эффективный классификатор, хорошо работающий на данных высокой размерности и способный строить нелинейные разделяющие поверхности.

Также была предусмотрена возможность создания ансамблевых моделей более высокого уровня, таких как **голосование (Voting)** и **стекинг (Stacking)**, для комбинирования предсказаний лучших базовых моделей с целью дальнейшего повышения качества классификации. Эти этапы подробно описаны в модуле `src/modeling/model_training.py` (класс `ModelTrainer`).

### 2.3.2 Подготовка данных и среды для обучения

Для обучения моделей использовался датасет, подготовленный на предыдущем этапе (см. Раздел 2.2), содержащий 20 отобранных признаков. Данные были разделены на обучающую (73 188 примеров) и тестовую (18 297 примеров) выборки в соотношении 80/20 со стратификацией по целевой переменной.

Учитывая значительный дисбаланс классов в целевой переменной `loyalty_target` (в данном запуске класс 'Отток' (0) составлял 12.63%, а класс 'Высоколояльные' (1) – 87.37%), при обучении моделей применялся механизм взвешивания классов. Это позволило придать больший вес менее представленному классу ('Отток'), чтобы модели не игнорировали его в процессе обучения.

### 2.3.3 Обучение и первоначальная оценка моделей

Все выбранные модели обучались на обучающей выборке. Процесс обучения и оценки был инкапсулирован в классе `ModelTrainer` (`src/modeling/model_training.py`), а детальная оценка и визуализация результатов производилась с помощью класса `ModelEvaluator` (`src/modeling/model_evaluation.py`).

Для первоначальной оценки качества моделей использовался набор стандартных метрик бинарной классификации:
*   **Accuracy:** Общая доля правильно классифицированных примеров.
*   **Precision (точность):** Доля истинно положительных классификаций среди всех положительных классификаций. Рассчитывалась для каждого класса и в макро-усредненном виде.
*   **Recall (полнота):** Доля истинно положительных классификаций среди всех фактически положительных примеров. Рассчитывалась для каждого класса и в макро-усредненном виде.
*   **F1-score:** Гармоническое среднее Precision и Recall. Рассчитывалась для каждого класса и в макро-усредненном виде (F1-macro).
*   **ROC AUC (площадь под ROC-кривой):** Метрика, оценивающая способность модели различать классы.
*   **Матрица ошибок (Confusion Matrix):** Для детального анализа ошибок классификации по каждому классу.

На этапе первоначального обучения и оценки все модели показали различную степень эффективности. Модели, основанные на градиентном бустинге (XGBoost, LightGBM), а также Random Forest, как правило, демонстрировали более высокие значения метрик F1-macro и ROC AUC по сравнению с логистической регрессией и SVM на данном наборе данных. Эти результаты согласуются с предварительными тестами, упомянутыми в.

Все обученные модели и их метрики сохранялись в едином файле (например, `output/models/trained_models_bundle.pkl`) для последующего анализа, оптимизации и выбора лучшей модели. 